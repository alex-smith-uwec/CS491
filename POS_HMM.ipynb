{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 29980,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-smith-uwec/CS491/blob/main/POS_HMM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This kernel is implementation of the file: https://github.com/vaibhavs4424/POS-Tagger-using-HMM/blob/master/POSTaggingUsingHMM.py\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "\n",
        "\n",
        "from nltk.corpus import brown\n",
        "# brown.tagged_sents()\n",
        "\n",
        "\n",
        "# Accessing the tagged sentences\n",
        "# nltk.download('universal_tagset')\n",
        "\n",
        "# brown_tagged_sents = brown.tagged_sents(tagset='universal')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL658GqKWMgG",
        "outputId": "bfb2c92b-a810-45b2-a112-17b686b577df"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching the first 2 sentences from the Brown corpus, tagged with part-of-speech\n",
        "tagged_sentences = brown.tagged_sents()[:2]\n",
        "\n",
        "for sentence in tagged_sentences:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YR0VCi7XjNK",
        "outputId": "5a5a3199-f0fc-4966-c411-53c2c59a089c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]\n",
            "[('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook implements parts of speech (POS) tagging using Hidden Markov Model (HMM). Implementation of Viterbi Algorithm is also shown later."
      ],
      "metadata": {
        "id": "Qwh-1cSZWMgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Say words = $[w_1\\ldots w_N]$ and tags = $[t_1\\ldots t_N]$.\n",
        "\n",
        " Then  $P(\\text{tags}\\vert\\text{words})$ is proportional to  $$\\prod P(t_i\\vert t_{i-1}) \\cdot P(w_i \\vert t_i)$$\n",
        "\n",
        " To find the best tag sequence for a given sequence of words, we want to find the tag sequence that maximizes $P(\\text{tags} | \\text{words})$"
      ],
      "metadata": {
        "id": "CbzU4ku-H6pJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "G_auS0dAWMgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brown.tagged_sents()"
      ],
      "metadata": {
        "trusted": true,
        "id": "MYqiEBBsWMgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KB2qf0hPHzUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Now, we will estimate $P(w_i|t_i)$ from corpus data:\n",
        "\n",
        "  $P(w_i | t_i)=\\displaystyle{\\frac{\\text{count}(w_i,t_i)}{\\text{count}(t_i)}}$"
      ],
      "metadata": {
        "id": "wUV4gsRbWMgN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "eK0FeermWMgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of all the unique tags from the corpus\n",
        "\n",
        "brown_word_tags=[]\n",
        "\n",
        "#Manually adding the start and the end tag\n",
        "for brown_sent in brown.tagged_sents():\n",
        "    brown_word_tags.append(('START','START'))\n",
        "\n",
        "    for words,tag in brown_sent:\n",
        "        brown_word_tags.extend([(tag[:2],words)])\n",
        "\n",
        "    brown_word_tags.append(('END','END'))\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "poqY0_AjWMgN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brown_word_tags[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inyoiFXBbpKd",
        "outputId": "cfda2b51-befe-45c1-8c70-a1a06bceb6e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('START', 'START'),\n",
              " ('AT', 'The'),\n",
              " ('NP', 'Fulton'),\n",
              " ('NN', 'County'),\n",
              " ('JJ', 'Grand'),\n",
              " ('NN', 'Jury'),\n",
              " ('VB', 'said'),\n",
              " ('NR', 'Friday'),\n",
              " ('AT', 'an'),\n",
              " ('NN', 'investigation')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the continuous frequency distribution for the words which are tagged\n",
        "cfd_tag_words=nltk.ConditionalFreqDist(brown_word_tags)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "2VEM3ReyWMgO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfd_tag_words['NN']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgD-frH9cuPQ",
        "outputId": "bbe09f2b-6a88-489a-acd1-9b6063bed67e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'time': 1555, 'man': 1148, 'Af': 994, 'years': 942, 'way': 883, 'people': 809, 'men': 736, 'world': 684, 'life': 676, 'year': 647, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the conditional probability distribution\n",
        "cpd_tag_words=nltk.ConditionalProbDist(cfd_tag_words,nltk.MLEProbDist)"
      ],
      "metadata": {
        "trusted": true,
        "id": "HDorjLKDWMgO"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The probability of an adjective (JJ) being 'smart' is\", cpd_tag_words[\"JJ\"].prob(\"smart\"))\n",
        "print(\"The probability of a verb (VB) being 'try' is\", cpd_tag_words[\"VB\"].prob(\"try\"))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJxg6zo8WMgO",
        "outputId": "b611f305-3296-463d-9ece-940f8c862aea"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of an adjective (JJ) being 'smart' is 0.00027780092785509904\n",
            "The probability of a verb (VB) being 'try' is 0.0010790559555256297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Estimating $P(t_i\\vert t_{i-1})$  from corpus data:\n",
        "\n",
        " $P(t_i | t_{i-1}) = \\displaystyle{\\frac{\\text{count}(t_{i-1}, t_i)}{\\text{count}(t_{i-1})}}$"
      ],
      "metadata": {
        "id": "bqzzCoMSWMgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brown_tags=[]\n",
        "for tag, words in brown_word_tags:\n",
        "    brown_tags.append(tag)"
      ],
      "metadata": {
        "trusted": true,
        "id": "0wuJGqlIWMgO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(brown_tags[0:25])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0Nu1qHooZZR",
        "outputId": "1bca471b-9cb2-44b9-ee38-96f113495fa7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['START', 'AT', 'NP', 'NN', 'JJ', 'NN', 'VB', 'NR', 'AT', 'NN', 'IN', 'NP', 'JJ', 'NN', 'NN', 'VB', '``', 'AT', 'NN', \"''\", 'CS', 'DT', 'NN', 'VB', 'NN']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make conditional frequency distribution: Count(t{i-1} ti)\n",
        "cfd_tags=nltk.ConditionalFreqDist(nltk.bigrams(brown_tags))"
      ],
      "metadata": {
        "trusted": true,
        "id": "BGegK0nHWMgP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make conditional probability distribution, using estimate: P(ti | t{i-1})\n",
        "cpd_tags=nltk.ConditionalProbDist(cfd_tags,nltk.MLEProbDist)"
      ],
      "metadata": {
        "trusted": true,
        "id": "XnmGBe4tWMgP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The probability of DT occuring after NN is : ', cpd_tags[\"NN\"].prob(\"DT\"))\n",
        "print('The probability of VB occuring after NN is : ', cpd_tags[\"NN\"].prob(\"VB\"))\n",
        "print('The probability of NN occuring after DT is : ',cpd_tags[\"DT\"].prob(\"VB\"))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5W156kdWMgP",
        "outputId": "2e0a7ab7-0c24-492e-dcdc-2c3ac9730dfb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of DT occuring after NN is :  0.0018349509874933604\n",
            "The probability of VB occuring after NN is :  0.0646359290427087\n",
            "The probability of NN occuring after DT is :  0.049661862149053895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## The probability of the tag sequence \"PP VB NN\" for the word sequence \"We love food\" is\n",
        " $P(START) \\cdot P(PP|START) \\cdot P(We | PP) \\cdot P(VB | PP) \\cdot P(love | VB) \\cdot P(TO | VB) \\cdot P(food | NN) \\cdot P(END | VB)$"
      ],
      "metadata": {
        "id": "GQsCT_lVWMgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob_tagsequence = cpd_tags[\"START\"].prob(\"PP\") * cpd_tag_words[\"PP\"].prob(\"We\") * \\\n",
        "                   cpd_tags[\"PP\"].prob(\"VB\") * cpd_tag_words[\"VB\"].prob(\"love\") * \\\n",
        "                   cpd_tags[\"VB\"].prob(\"NN\") * cpd_tag_words[\"PP\"].prob(\"food\") * \\\n",
        "                   cpd_tags[\"NN\"].prob(\"END\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "-u5EwpLEWMgQ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The probability of sentence 'We love food' having the tag sequence 'START PP VB PP END' is : \", prob_tagsequence)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po0Nxh2aWMgQ",
        "outputId": "42414b25-50cb-4c58-cb4d-94fba25d9711"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of sentence 'We love food' having the tag sequence 'START PP VB PP END' is :  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Viterbi:\n",
        "# If we have a word sequence, what is the best tag sequence?\n",
        "#\n",
        "# The method above lets us determine the probability for a single tag sequence.\n",
        "# But in order to find the best tag sequence, we need the probability\n",
        "# for _all_ tag sequence.\n",
        "# What Viterbi gives us is just a good way of computing all those many probabilities\n",
        "# as fast as possible.\n",
        "\n",
        "\n",
        "distinct_brown_tags=set(brown_tags)"
      ],
      "metadata": {
        "trusted": true,
        "id": "J--SPxz-WMgQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentences=[\"I\",\"love\",\"spicy\",\"food\"]\n",
        "len_sample_sentence=len(sample_sentences)"
      ],
      "metadata": {
        "trusted": true,
        "id": "EuVDAC77WMgQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for each step i in 1 .. sentlen,\n",
        "# store a dictionary\n",
        "# that maps each tag X\n",
        "# to the probability of the best tag sequence of length i that ends in X\n",
        "\n",
        "\n",
        "viterbi_tags={}\n",
        "viterbi_backpointer={}\n",
        "\n",
        "for tag in distinct_brown_tags:\n",
        "    if tag==\"START\":\n",
        "        continue\n",
        "    viterbi_tags[tag]=cpd_tags[\"START\"].prob(tag)*cpd_tag_words[tag].prob(sample_sentences[0])\n",
        "    viterbi_backpointer[tag]=\"START\""
      ],
      "metadata": {
        "trusted": true,
        "id": "En0Pa4fTWMgQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for each step i in 1 .. sentlen,\n",
        "# store a dictionary\n",
        "# that maps each tag X\n",
        "# to the probability of the best tag sequence of length i that ends in X\n",
        "\n",
        "\n",
        "\n",
        "viterbi_main=[]\n",
        "backpointer_main=[]\n",
        "\n",
        "viterbi_main.append(viterbi_tags)\n",
        "backpointer_main.append(viterbi_backpointer)\n",
        "\n",
        "current_best=max(viterbi_tags.keys(),key=lambda tag: viterbi_tags[tag])\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "o-1ImWxWWMgR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Word\", \"'\" + sample_sentences[0] + \"'\", \"current best two-tag sequence:\", viterbi_backpointer[current_best], current_best)\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlGtnNEVWMgR",
        "outputId": "95efe56a-41ff-4e86-8424-7d4a911326ba"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 'I' current best two-tag sequence: START PP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for index in range(1,len_sample_sentence):\n",
        "    curr_viterbi={}\n",
        "    curr_backpointer={}\n",
        "    prev_viterbi=viterbi_main[-1]\n",
        "\n",
        "    for brown_tag in distinct_brown_tags:\n",
        "\n",
        "        if brown_tag != \"START\":\n",
        "            # if this tag is X and the current word is w, then\n",
        "            # find the previous tag Y such that\n",
        "            # the best tag sequence that ends in X\n",
        "            # actually ends in Y X\n",
        "            # that is, the Y that maximizes\n",
        "            # prev_viterbi[ Y ] * P(X | Y) * P( w | X)\n",
        "            # The following command has the same notation\n",
        "            # that you saw in the sorted() command.\n",
        "            prev_best = max(prev_viterbi.keys(),\n",
        "                                key=lambda prevtag: \\\n",
        "                                    prev_viterbi[prevtag] * cpd_tags[prevtag].prob(brown_tag) * cpd_tag_words[brown_tag].prob(\n",
        "                                        sample_sentences[index]))\n",
        "\n",
        "            curr_viterbi[brown_tag] = prev_viterbi[prev_best] * \\\n",
        "                                cpd_tags[prev_best].prob(brown_tag) * cpd_tag_words[brown_tag].prob(sample_sentences[index])\n",
        "            curr_backpointer[brown_tag] = prev_best\n",
        "\n",
        "    current_best = max(curr_viterbi.keys(), key=lambda tag: curr_viterbi[tag])\n",
        "    print(\"Word\", \"'\" + sample_sentences[index] + \"'\", \"current best two-tag sequence:\", curr_backpointer[current_best], current_best)\n",
        "\n",
        "\n",
        "    viterbi_main.append(curr_viterbi)\n",
        "    backpointer_main.append(curr_backpointer)\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYycVLPYWMgR",
        "outputId": "0c6ec1e5-463a-4005-c28b-6ec7b92d53c3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 'love' current best two-tag sequence: PP NN\n",
            "Word 'spicy' current best two-tag sequence: VB JJ\n",
            "Word 'food' current best two-tag sequence: JJ NN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now find the probability of each tag\n",
        "# to have \"END\" as the next tag,\n",
        "# and use that to find the overall best sequence\n",
        "\n",
        "\n",
        "\n",
        "prev_viterbi = viterbi_main[-1]\n",
        "prev_best = max(prev_viterbi.keys(),\n",
        "                    key=lambda prev_tag: prev_viterbi[prev_tag] * cpd_tags[prev_tag].prob(\"END\"))\n",
        "\n",
        "prob_tag_sequence = prev_viterbi[prev_best] * cpd_tags[prev_best].prob(\"END\")\n",
        "\n",
        "\n",
        "best_tag_sequence = [\"END\", prev_best]\n",
        "# invert the list of backpointers\n",
        "backpointer_main.reverse()\n",
        "\n",
        "# go backwards through the list of backpointers\n",
        "# (or in this case forward, because we have inverter the backpointer list)\n",
        "# in each case:\n",
        "# the following best tag is the one listed under\n",
        "# the backpointer for the current best tag\n",
        "current_best_tag = prev_best\n",
        "for backpointer in backpointer_main:\n",
        "    best_tag_sequence.append(backpointer[current_best_tag])\n",
        "    current_best_tag = backpointer[current_best_tag]\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "gDi2wsITWMgR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_tag_sequence.reverse()"
      ],
      "metadata": {
        "trusted": true,
        "id": "d_HVfPEeWMgR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The sentence given is :\")\n",
        "for word in sample_sentences:\n",
        "    print (word,\"\",)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkB7WJLKWMgR",
        "outputId": "bf6e4467-98b2-4aab-c642-7a8192284515"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentence given is :\n",
            "I \n",
            "love \n",
            "spicy \n",
            "food \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best tag sequence using HMM for the given sentence is : \")\n",
        "\n",
        "\n",
        "for best_tag in best_tag_sequence:\n",
        "    print (best_tag, \"\",)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOI968KDWMgS",
        "outputId": "d111644e-af8f-433c-c287-71aeaa9ca3e6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best tag sequence using HMM for the given sentence is : \n",
            "START \n",
            "PP \n",
            "VB \n",
            "JJ \n",
            "NN \n",
            "END \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The probability of the best tag sequence printed above is given by : \", prob_tag_sequence)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae33FTN9WMgS",
        "outputId": "8861bc41-f481-472c-9d6f-dff39ea84028"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of the best tag sequence printed above is given by :  1.085507090627119e-18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "16r4NdaSWMgS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}